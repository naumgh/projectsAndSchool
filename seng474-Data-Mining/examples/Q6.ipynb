{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8dUVaOV1_8i"
      },
      "source": [
        "# Analysis of Medline Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtx8RocFFfA0"
      },
      "source": [
        "**To be run on Google Colab**.\n",
        "\n",
        "**The following cell can take long, about 3 min**. Only execute it once per session.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "Flc_bBaTtJpl"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop2.tgz\n",
        "!tar xf spark-3.3.2-bin-hadoop2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "LRIKvYKRFbGz"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop2\"\n",
        "\n",
        "import findspark\n",
        "findspark.init(\"spark-3.3.2-bin-hadoop2\")# SPARK_HOME\n",
        "\n",
        "import csv\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRmdcSNYuAAC",
        "outputId": "6fb77387-8c59-4263-eeb9-bb8ad655e0c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-12 23:37:31--  http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip.12’\n",
            "\n",
            "\rml-latest-small.zip   0%[                    ]       0  --.-KB/s               \rml-latest-small.zip 100%[===================>] 955.28K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-03-12 23:37:31 (7.89 MB/s) - ‘ml-latest-small.zip.12’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "replace ml-latest-small/links.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "replace ml-latest-small/tags.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "replace ml-latest-small/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip\n",
        "!mv ml-latest-small/ratings.csv .\n",
        "!mv ml-latest-small/movies.csv .\n",
        "linesRDD = sc.textFile(\"ratings.csv\")\n",
        "\n",
        "linesRDD = linesRDD.map(lambda line: line.split(\"|\"))\n",
        "\n",
        "#print(linesRDD.collect())\n",
        "\n",
        "firstLine = linesRDD.first()\n",
        "linesRDD = linesRDD.filter(lambda x:firstLine != x)\n",
        "#print(linesRDD.collect())\n",
        "\n",
        "#smcnt = rdd.map(lambda x: (x,1)).reduce(lambda t,r: (t[0]+r[0],t[1]+r[1]))\n",
        "\n",
        "#print(smcnt)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#topics = medline_lists.flatMap(lambda topiclist: topiclist)\n",
        "#print(topics.take(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu4I8kMwOTp_",
        "outputId": "ef668e57-07bf-4ffd-c998-cb9db8f5a551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('user1', 4.366379310344827), ('user2', 3.9482758620689653), ('user4', 3.5555555555555554), ('user5', 3.6363636363636362), ('user6', 3.4936305732484074)]\n",
            "[('movieid1', 3.9209302325581397), ('movieid3', 3.2596153846153846), ('movieid6', 3.946078431372549), ('movieid47', 3.9753694581280787), ('movieid70', 3.5090909090909093)]\n"
          ]
        }
      ],
      "source": [
        "new_rdd = linesRDD.map(lambda x: x[0].split(\",\"))\n",
        "#print(new_rdd.take(10))\n",
        "\n",
        "#user id = u1\n",
        "#movie id = m1\n",
        "#rating = 4\n",
        "#timestamp = 964982703\n",
        "\n",
        "new_rdd = new_rdd.map(lambda x: {'user':'user'+x[0], 'movieid':'movieid'+x[1], 'rating':float(x[2]), 'timestamp':float(x[3])})\n",
        "#print(new_rdd.take(5))\n",
        "\n",
        "#user rdd\n",
        "\n",
        "user_rdd = new_rdd.map(lambda x:(x['user'],x['rating']))\n",
        "#print(user_rdd.take(5))\n",
        "\n",
        "seqFunc = (lambda x,y: (x[0] + y, x[1] + 1))\n",
        "combFunc = (lambda x,y: (x[0] + y[0], x[1] + y[1]))\n",
        "user_rdd = user_rdd.aggregateByKey((0, 0), seqFunc,combFunc)\n",
        "#user_rdd.collect()\n",
        "\n",
        "user_rdd = user_rdd.map(lambda x: (x[0], x[1][0] / x[1][1]))\n",
        "#user_rdd.collect()\n",
        "\n",
        "#movie rdd\n",
        "\n",
        "movie_rdd = new_rdd.map(lambda x:(x['movieid'],x['rating']))\n",
        "#print(movie_rdd.take(5))\n",
        "\n",
        "seqFunc = (lambda x,y: (x[0] + y, x[1] + 1))\n",
        "combFunc = (lambda x,y: (x[0] + y[0], x[1] + y[1]))\n",
        "movie_rdd_agg = movie_rdd.aggregateByKey((0, 0), seqFunc,combFunc)\n",
        "#print(movie_rdd.collect())\n",
        "\n",
        "movie_rdd_avg = movie_rdd_agg.map(lambda x: (x[0], x[1][0] / x[1][1]))\n",
        "#movie_rdd.collect()\n",
        "\n",
        "user_movie_rdd = user_rdd.union(movie_rdd_avg) #im just going to output them seperately\n",
        "\n",
        "\n",
        "print(user_rdd.take(5))\n",
        "print(movie_rdd_avg.take(5))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqq4-VlhEUiz",
        "outputId": "ce82608f-3504-46c7-d55d-b6b890f16407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Fantasy', 3.4910005070136894), ('Thriller', 3.4937055799183425), ('Romance', 3.5065107040388437), ('Western', 3.583937823834197), ('Sci-Fi', 3.455721162210752), ('Drama', 3.6561844113718758), ('Musical', 3.5636781053649105), ('Adventure', 3.5086089151939075), ('Comedy', 3.3847207640898267), ('War', 3.8082938876312), ('Film-Noir', 3.920114942528736), ('Children', 3.412956125108601), ('Action', 3.447984331646809), ('Horror', 3.258195034974626), ('Documentary', 3.797785069729286), ('IMAX', 3.618335343787696), ('Animation', 3.6299370349170004), ('Crime', 3.658293867274144), ('Mystery', 3.632460255407871), ('(no genres listed)', 3.4893617021276597)]\n"
          ]
        }
      ],
      "source": [
        "#now we do movies.csv\n",
        "\n",
        "datafile = open('movies.csv', 'r')\n",
        "myreader = csv.reader(datafile)\n",
        "\n",
        "movieGenres = {}\n",
        "for row in myreader:\n",
        "  if row != ['movieId','title','genres']:\n",
        "    movieGenres[row[0]] = row[2].split('|')\n",
        "#print(movieGenres)\n",
        "\n",
        "m_rdd = sc.parallelize([('movieid'+key,value) for key, value in movieGenres.items()])\n",
        "\n",
        "#print(m_rdd.take(5))\n",
        "\n",
        "#print(user_movie_rdd.take(5))\n",
        "#print(movie_rdd.take(5))\n",
        "\n",
        "\n",
        "joined_rdd = movie_rdd.join(m_rdd)\n",
        "#print(joined_rdd.take(5))\n",
        "\n",
        "only_1 = joined_rdd.filter(lambda x: x[0] == 'movieid1')\n",
        "#print(only_1.collect())\n",
        "\n",
        "tuple_rdd = joined_rdd.flatMap(lambda x: [(genre,x[1][0]) for genre in x[1][1]])\n",
        "#print(tuple_rdd.take(5))\n",
        "\n",
        "seqFunc = (lambda x,y: (x[0] + y, x[1] + 1))\n",
        "combFunc = (lambda x,y: (x[0] + y[0], x[1] + y[1]))\n",
        "tuple_rdd = tuple_rdd.aggregateByKey((0, 0), seqFunc,combFunc)\n",
        "#print(tuple_rdd.take(5))\n",
        "\n",
        "\n",
        "tuple_rdd = tuple_rdd.map(lambda x: (x[0], x[1][0] / x[1][1]))\n",
        "print(tuple_rdd.collect())\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}